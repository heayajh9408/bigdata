03/31

* 케라스를 이용한 인공신경망 구현
 o 활성화 함수
  - 입력 신호가 일정 크기 이상일 때만 신호를 전달하는 메커니즘을 모방한 함수
  - Softmax, Sigmoid, tanh, Binary step, Gaussian, ReLU
 o 인공신경망
  - 입력층, 은닉층, 출력층으로 구성
  - 입력층의 뉴런의 수는 입력 데이터의 수, 출력층은 분류 문제를 해결할 경우에는 분류의 수와 일치
  - DNN은 은닉층이 여러 개로 구성된 다층 인공신경망
 o Keras
  - 유저가 손쉽게 딥 러닝을 구현할 수 있도록 도와주는 상위 레벨의 인터페이스

* 순환 신경망(RNN)
 o 입력과 출력을 시퀀스로 처리하는 모델
  - 은닉층에서 활성화 함수를 통해 나온 값을 출력층으로 보내면서, 다시 은닉층의 다음 계산의 입력으로 보냄
 o pad_sequences
  - sequence를 훈련가능한 데이터로 만드는 것
  - 모든 데이터에 대해서 0을 추가하여 길이를 맞춰줌
  - maxlen 값에 따라 모든 데이터의 길이를 맞추며, padding의 인자로 'pre' 시 길이가 짧은 데이터의 앞을 0으로 채움
 o to_categorical
  - 훈련데이터를 훈련 시키기 이전에 y에 대해서 원-핫 인코딩 필요

# 과정: 데이터 준비 -> 데이터 셋 정의 -> 모델 구성 -> 모델학습 과정 설정 -> 모델학습 -> 모델평가 -> 사용
# LSTM은 기존 코드와 크게 다른 점은 없고 모형을 만드는 클래스가 다름
